{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f7d2e-427c-4370-9626-5e146459cb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from datetime import timedelta\n",
    "from nltk.corpus import stopwords \n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='iframe'\n",
    "import re\n",
    "from util import *\n",
    "from hdbscan import HDBSCAN\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, pipeline\n",
    "from bertopic.representation import TextGeneration\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234789f0-ad9e-4eec-a64f-aede5c0d5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carica il CSV\n",
    "df_deghi = pd.read_csv(\"deghi_dataset.csv\", sep=\"§\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0af6b5-6ef1-4d75-bf08-cc0b6c40cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deghi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160a15c-526b-4fd1-9f94-cd971f861839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def puliscidataset(df):\n",
    "\n",
    "        df['Text']=df['Text'].str.lower() #minuscolo\n",
    "\n",
    "        symbols = \"£x!\\\"#$%&()*+-/<=>?@[\\]^_`{|}~\\n\"           #punteggiatura \n",
    "\n",
    "        for i in symbols:\n",
    "                         df['Text'] = df['Text'].str.replace(i,' ',regex=False)\n",
    "\n",
    "        df['Text'] = df['Text'].str.replace(\"'\",' ',regex=False)\n",
    "        df['Text'] = df['Text'].str.replace('€', 'euro ',regex=True)\n",
    "\n",
    "        df=df[df['Text'].notna()]\n",
    "\n",
    "        df['Text'] = df['Text'].str.replace('\\d+', '',regex=False)\n",
    "            \n",
    "        #rimuovi numeri    \n",
    "        df[\"Text\"]=df[\"Text\"].apply(lambda x: ' '.join([i for i in x.split() if not i.isdigit()]))    \n",
    "    \n",
    "        # Rimuovi parole che contengono numeri (parole come  bc \"pe435st200\")\n",
    "        #df['Nota'] = df['Nota'].apply(lambda x: ' '.join([i for i in x.split() if not re.search(r'\\d', i)]))\n",
    "       \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c17c266-6951-421e-8d9f-5e26b104ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deghi=puliscidataset(df_deghi).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520b3bd-f7e2-45e4-93a7-a460f2369843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta parole e caratteri\n",
    "df_deghi[\"n_parole\"] = df_deghi[\"Text\"].astype(str).apply(lambda x: len(x.split()))\n",
    "df_deghi[\"n_caratteri\"] = df_deghi[\"Text\"].astype(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b677c0a-104c-45cb-a9c9-016f3f8ce0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiche descrittive\n",
    "print(df_deghi[[\"n_parole\", \"n_caratteri\"]].describe())\n",
    "\n",
    "# Distribuzione lunghezze\n",
    "print(df_deghi[\"n_parole\"].value_counts().sort_index().head(20))  # primi 20 valori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7dc4b4d-ba37-41a5-b21e-b405f43f44ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_deghi[\"n_parole\"].hist(bins=50, figsize=(10,5))\n",
    "plt.xlabel(\"Numero di parole per recensione\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "plt.title(\"Distribuzione lunghezza recensioni Deghi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ffccc-d199-43c4-9095-248527b84a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# carica modello italiano per split in frasi\n",
    "nlp = spacy.load(\"it_core_news_sm\")\n",
    "\n",
    "\n",
    "def chunk_text_by_sentences(text, max_words=40, min_words=20):\n",
    "    \"\"\"\n",
    "    Divide il testo in blocchi di frasi.\n",
    "    - max_words = lunghezza massima di un blocco\n",
    "    - min_words = lunghezza minima (se una frase è troppo corta, la unisce a quella successiva)\n",
    "    \"\"\"\n",
    "    doc = nlp(str(text))\n",
    "    chunks, current_chunk, current_len = [], [], 0\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        words = sent.text.split()\n",
    "        if current_len + len(words) > max_words and current_len >= min_words:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk, current_len = [], 0\n",
    "        current_chunk.extend(words)\n",
    "        current_len += len(words)\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "    return chunks\n",
    "\n",
    "# funzione principale\n",
    "def make_chunked_dataframe(df, text_col=\"Text\", id_col=\"IdReview\", max_words=120, min_words=200):\n",
    "    \"\"\"\n",
    "    Ritorna un nuovo dataframe con le recensioni spezzate in chunk.\n",
    "    - Se una recensione ha <= min_words parole, resta intera.\n",
    "    - Se ha > min_words parole, viene divisa in blocchi di max_words.\n",
    "    \"\"\"\n",
    "    docs_chunked = []\n",
    "    ids = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        text = str(row[text_col])\n",
    "        n_words = len(text.split())\n",
    "        if n_words > min_words:\n",
    "            for chunk in chunk_text_by_sentences(text, max_words=max_words):\n",
    "                docs_chunked.append(chunk)\n",
    "                ids.append(row[id_col])\n",
    "        else:\n",
    "            docs_chunked.append(text)\n",
    "            ids.append(row[id_col])\n",
    "\n",
    "    return pd.DataFrame({id_col: ids, \"Chunk\": docs_chunked})\n",
    "\n",
    "# esempio di utilizzo\n",
    "df_chunked = make_chunked_dataframe(df_deghi, text_col=\"Text\", id_col=\"IdReview\",\n",
    "                                    max_words=20, min_words=10)\n",
    "\n",
    "print(df_chunked.head())\n",
    "print(\"Dimensioni dataframe originale:\", df_deghi.shape)\n",
    "print(\"Dimensioni dataframe chunked:\", df_chunked.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec2759-51fd-4e61-bdd7-305aa934334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conta parole e caratteri\n",
    "df_chunked[\"n_parole\"] = df_chunked[\"Chunk\"].astype(str).apply(lambda x: len(x.split()))\n",
    "df_chunked[\"n_caratteri\"] = df_chunked[\"Chunk\"].astype(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a39317-e25b-4443-8799-7bd35632469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se vuoi un istogramma (facoltativo)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_chunked[\"n_parole\"].hist(bins=50, figsize=(10,5))\n",
    "plt.xlabel(\"Numero di parole per recensione\")\n",
    "plt.ylabel(\"Frequenza\")\n",
    "plt.title(\"Distribuzione lunghezza recensioni Deghi\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab7cf99-f891-4eae-820f-be3393afa059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiche descrittive\n",
    "print(df_chunked[[\"n_parole\", \"n_caratteri\"]].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9a34e2-4a35-45f2-9695-fbae7d43fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prendi la colonna 'Text' come lista\n",
    "docs = df_chunked[\"Chunk\"].dropna().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b18c41-dd63-4805-93ae-eb89d3f5c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cd5c4-d053-45d7-9764-721d0f42ca29",
   "metadata": {},
   "source": [
    "# Traduce le singole note in vettori embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a37c30d-df35-40af-b00c-faa9cf55db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embedding_model = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "#embeddings = embedding_model.encode(df_chunked[\"Chunk\"].tolist(), show_progress_bar=True)\n",
    "# modello monolingua italiano\n",
    "#embedding_model = SentenceTransformer(\"nickprock/sentence-bert-base-italian-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac12d78-d966-4267-910e-1ec18d392373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic.representation import KeyBERTInspired\n",
    "prompt = \"\"\"<|system|>Sei un assistete che analizza documenti da un crm di una azienda di mobili per fornire ad un dirigente aspetti critici e negativi che appaiono nei documenti</s>\n",
    "<|user|>\n",
    "I seguenti documenti sono presi da un CRM di assistenza clienti di una azienda che vende mobili d'arredamento:\n",
    "[DOCUMENTS]\n",
    "\n",
    "Il tema è descritto dalle seguenti parole chiave:  '[KEYWORDS]'.\n",
    "\n",
    "Sulla base delle informazioni sopra, puoi fornire una breve etichetta del topic di massimo 5 parole?</s>\n",
    "<|assistant|>\"\"\"\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-Nemo-Instruct-2407\")\n",
    "\n",
    "generator = pipeline(\n",
    "    model=model, tokenizer=tokenizer,\n",
    "    task='text-generation',\n",
    "    max_new_tokens=350,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "# Text generation with Zephyr\n",
    "minstral = TextGeneration(generator, prompt=prompt)\n",
    "representation_model = {\"KeyBERT\": KeyBERTInspired(),\n",
    "                        \"LLM\": minstral}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7690e818-9dad-410c-85e0-e682a5d48e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.dimensionality import BaseDimensionalityReduction\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265482e-9af8-4e2f-b5f9-d8de371b53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(\n",
    "    n_neighbors=30,\n",
    "    n_components=5,\n",
    "    min_dist=0.2,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=15,\n",
    "    min_samples=10,\n",
    "    gen_min_span_tree=True, \n",
    "    prediction_data=False,\n",
    "    cluster_selection_method=\"eom\"\n",
    ")\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# stopword italiane e inglesi\n",
    "stop_it = stopwords.words(\"italian\")\n",
    "stop_en = stopwords.words(\"english\")\n",
    "\n",
    "# unisci le due liste\n",
    "stop_words = list(set(stop_it + stop_en))\n",
    "\n",
    "# Fine-tune topic representations after training BERTopic\n",
    "vectorizer_model = CountVectorizer(stop_words=stop_words, ngram_range=(1, 2), min_df=5)\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ccdc61-6937-415d-bc8d-02fa481b38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(umap_model=umap_model,hdbscan_model=hdbscan_model,embedding_model=embedding_model,representation_model=representation_model,ctfidf_model=ctfidf_model,  vectorizer_model=vectorizer_model,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b8f741-c2f1-4fe0-ae9d-4800d586ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7d7a23-5583-453b-9035-bd22a2a8d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().to_csv('../result/topic_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d6cac-ddf6-4e53-a1db-8ac151b2e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc474aa-5d03-460c-973f-df75be1f0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_hierarchy()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17a6096-8d4e-454c-a172-e4879260fdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datamapplot\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f280b375-f1cd-401b-8124-c05c9aa1ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7c607-7a5b-4b99-9154-80256bf49532",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = UMAP(n_neighbors=15, n_components=2, min_dist=0.0, metric='cosine', random_state=42).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7545f4-ec9c-417d-86bc-ed0ee8c2366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a label for each document\n",
    "llm_labels = [re.sub(r'\\W+', ' ', label[0][0].split(\"\\n\")[0].replace('\"', '')) for label in topic_model.get_topics(full=True)[\"LLM\"].values()]\n",
    "llm_labels = [label if label else \"Unlabelled\" for label in llm_labels]\n",
    "all_labels = [llm_labels[topic+topic_model._outliers] if topic != -1 else \"Unlabelled\" for topic in topics]\n",
    "\n",
    "# Run the visualization\n",
    "datamapplot.create_plot(\n",
    "    reduced_embeddings,\n",
    "    all_labels,\n",
    "    label_font_size=11,\n",
    "    title=\"Deghi - BERTopic\",\n",
    "    sub_title=\"Topics generati con  mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    label_wrap_width=20,\n",
    "    use_medoids=True,\n",
    "    #logo=bertopic_logo,\n",
    "    #logo_width=0.16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e0bf4-52fc-48be-be20-a00512e8093c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
